{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as sc\n",
    "import glob\n",
    "import shutil\n",
    "import ntpath\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql.functions import date_format\n",
    "findspark.init()\n",
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType([StructField(\"DATE\",StringType(),True),\n",
    "                   StructField(\"VIN\",IntegerType(),True),\n",
    "                   StructField(\"IIN\",IntegerType(),True),\n",
    "                   StructField(\"VOUT\",IntegerType(),True),\n",
    "                   StructField(\"VBATT\",IntegerType(),True),\n",
    "                   StructField(\"IBATT\",IntegerType(),True),\n",
    "                   StructField(\"TEMP\",IntegerType(),True),\n",
    "                   StructField(\"JP\",StringType(),True),\n",
    "                   StructField(\"CNT\",IntegerType(),True),\n",
    "                   StructField(\"STS\",IntegerType(),True),\n",
    "                   StructField(\"MIN\",IntegerType(),True),\n",
    "                   StructField(\"POWER\",IntegerType(),True),\n",
    "                   StructField(\"AUTOBCKLIGHT\",IntegerType(),True),\n",
    "                   StructField(\"CURRLIGHT\",IntegerType(),True),\n",
    "                   StructField(\"BRIGHTNESS\",IntegerType(),True),\n",
    "                   StructField(\"PAN1VOLT\",IntegerType(),True),\n",
    "                   StructField(\"PAN1CURR\",IntegerType(),True),\n",
    "                   StructField(\"BCK1VOLT\",IntegerType(),True),\n",
    "                   StructField(\"BCK1CURR\",IntegerType(),True),\n",
    "                   StructField(\"RSSI\",IntegerType(),True),StructField(\"Batt_id\",StringType(),False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- VIN: integer (nullable = true)\n",
      " |-- IIN: integer (nullable = true)\n",
      " |-- VOUT: integer (nullable = true)\n",
      " |-- VBATT: integer (nullable = true)\n",
      " |-- IBATT: integer (nullable = true)\n",
      " |-- TEMP: integer (nullable = true)\n",
      " |-- JP: string (nullable = true)\n",
      " |-- CNT: integer (nullable = true)\n",
      " |-- STS: integer (nullable = true)\n",
      " |-- MIN: integer (nullable = true)\n",
      " |-- POWER: integer (nullable = true)\n",
      " |-- AUTOBCKLIGHT: integer (nullable = true)\n",
      " |-- CURRLIGHT: integer (nullable = true)\n",
      " |-- BRIGHTNESS: integer (nullable = true)\n",
      " |-- PAN1VOLT: integer (nullable = true)\n",
      " |-- PAN1CURR: integer (nullable = true)\n",
      " |-- BCK1VOLT: integer (nullable = true)\n",
      " |-- BCK1CURR: integer (nullable = true)\n",
      " |-- RSSI: integer (nullable = true)\n",
      " |-- Batt_id: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark predictive maintenance\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\").config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .getOrCreate()\n",
    "df = spark.createDataFrame(spark.sparkContext.emptyRDD(),schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leggere i miei CSV con Pyspark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Giorno: 16/10/2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+\n",
      "|_c0|               DATE|  VIN|IIN| VOUT|VBATT|IBATT|TEMP| JP|  CNT|STS|MIN|  POWER|AUTOBCKLIGHT|CURRLIGHT|BRIGHTNESS|PAN1VOLT|PAN1CURR|BCK1VOLT|BCK1CURR| RSSI|     host_id|\n",
      "+---+-------------------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+\n",
      "|  0|2020-11-01 00:00:50|29168|679|29097|29062|  708| 270|OFF|13957|  1|0.0|20575.0|        -1.0|     -1.0|      -1.0|    -1.0|    -1.0|    -1.0|    -1.0|-73.0|814U01M70006|\n",
      "|  1|2020-11-01 00:01:49|29167|626|29097|29062|  687| 270|OFF|13958|  1|0.0|19965.0|        -1.0|     -1.0|      -1.0|    -1.0|    -1.0|    -1.0|    -1.0|-75.0|814U01M70006|\n",
      "+---+-------------------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CSV_DF=spark.read.csv('./Days/20201102_030001.csv',header=True,sep=\";\",inferSchema=True)\n",
    "CSV_DF=CSV_DF.withColumnRenamed(\"Batt_id\", \"host_id\")\n",
    "CSV_DF.show(2)\n",
    "CSV_DF=CSV_DF.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|      date|  VIN|IIN| VOUT|VBATT|IBATT|TEMP| JP|  CNT|STS|MIN|  POWER|AUTOBCKLIGHT|CURRLIGHT|BRIGHTNESS|PAN1VOLT|PAN1CURR|BCK1VOLT|BCK1CURR| RSSI|     host_id|    time|\n",
      "+----------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|2020-11-01|29168|679|29097|29062|  708| 270|OFF|13957|  1|0.0|20575.0|        -1.0|     -1.0|      -1.0|    -1.0|    -1.0|    -1.0|    -1.0|-73.0|814U01M70006|00:00:50|\n",
      "|2020-11-01|29167|626|29097|29062|  687| 270|OFF|13958|  1|0.0|19965.0|        -1.0|     -1.0|      -1.0|    -1.0|    -1.0|    -1.0|    -1.0|-75.0|814U01M70006|00:01:49|\n",
      "|2020-11-01|29167|650|29097|29053|  631| 270|OFF|13959|  1|0.0|18332.0|        -1.0|     -1.0|      -1.0|    -1.0|    -1.0|    -1.0|    -1.0|-73.0|814U01M70006|00:02:48|\n",
      "+----------+-----+---+-----+-----+-----+----+---+-----+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CSV_DF = CSV_DF.withColumn('time', F.date_format(F.col('DATE').cast('timestamp'), 'HH:mm:ss').alias('time'))\n",
    "CSV_DF = CSV_DF.withColumn(\"date\", F.col('DATE').cast('date').alias('date'))\n",
    "CSV_DF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Giorno 29/10/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DF1=spark.read.csv('./Days/20201103_030001.csv',header=True,sep=\";\",inferSchema=True)\n",
    "CSV_DF1=CSV_DF1.withColumnRenamed(\"Batt_id\", \"host_id\")\n",
    "CSV_DF1=CSV_DF1.drop(\"_c0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-----+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|      date|  VIN|IIN| VOUT|VBATT|IBATT|TEMP| JP|   CNT|STS|MIN|POWER|AUTOBCKLIGHT|CURRLIGHT|BRIGHTNESS|PAN1VOLT|PAN1CURR|BCK1VOLT|BCK1CURR| RSSI|     host_id|    time|\n",
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-----+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|2020-11-02|29238|644|28848|29140|  592| 285|OFF|593890|  1|  0|17250|         1.0|      1.0|       0.0| 11916.0|   510.0| 24036.0|   419.0|-87.0|814U01M70009|00:00:11|\n",
      "|2020-11-02|29240|623|28848|29140|  595| 285|OFF|593891|  1|  0|17338|         1.0|      1.0|       0.0| 11916.0|   510.0| 24032.0|   419.0|  0.0|814U01M70009|00:01:10|\n",
      "|2020-11-02|29240|596|28848|29137|  604| 285|OFF|593892|  1|  0|17598|         1.0|      1.0|       0.0| 11916.0|   510.0| 24032.0|   419.0|-87.0|814U01M70009|00:02:09|\n",
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-----+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CSV_DF1 = CSV_DF1.withColumn('time', F.date_format(F.col('DATE').cast('timestamp'), 'HH:mm:ss').alias('time'))\n",
    "CSV_DF1 = CSV_DF1.withColumn(\"date\", F.col('DATE').cast('date').alias('date'))\n",
    "CSV_DF1.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Giorno 30/10/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|      date|  VIN|IIN| VOUT|VBATT|IBATT|TEMP| JP|   CNT|STS|MIN|  POWER|AUTOBCKLIGHT|CURRLIGHT|BRIGHTNESS|PAN1VOLT|PAN1CURR|BCK1VOLT|BCK1CURR| RSSI|     host_id|    time|\n",
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "|2020-11-03|29237|602|28890|29135|  588| 230|OFF|595355|  1|0.0|17131.0|           1|      1.0|       0.0| 11916.0|   510.0| 24036.0|   419.0|-85.0|814U01M70009|00:00:01|\n",
      "|2020-11-03|29237|636|28890|29136|  592| 235|OFF|595356|  1|0.0|17248.0|           1|      1.0|       0.0| 11916.0|   510.0| 24036.0|   419.0|-85.0|814U01M70009|00:01:00|\n",
      "|2020-11-03|29238|613|28890|29138|  593| 235|OFF|595357|  1|0.0|17278.0|           1|      1.0|       0.0| 11916.0|   510.0| 24036.0|   419.0|-87.0|814U01M70009|00:01:59|\n",
      "+----------+-----+---+-----+-----+-----+----+---+------+---+---+-------+------------+---------+----------+--------+--------+--------+--------+-----+------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CSV_DF2=spark.read.csv('./Days/20201104_030001.csv',header=True,sep=\";\",inferSchema=True)\n",
    "CSV_DF2=CSV_DF2.withColumnRenamed(\"Batt_id\", \"host_id\")\n",
    "CSV_DF2=CSV_DF2.drop(\"_c0\")\n",
    "CSV_DF2=CSV_DF2.withColumn('time', F.date_format(F.col('DATE').cast('timestamp'), 'HH:mm:ss').alias('time'))\n",
    "CSV_DF2=CSV_DF2.withColumn(\"date\", F.col('DATE').cast('date').alias('date'))\n",
    "CSV_DF2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV_DF['date']=''\n",
    "# CSV_DF['time']=''\n",
    "# for i in range(CSV_DF.shape[0]):\n",
    "#     aus=CSV_DF['DATE'][i]\n",
    "#     if type(aus) == str:\n",
    "#         CSV_DF['date'][i]=datetime.strptime(aus, '%Y-%m-%d %H:%M:%S').date()\n",
    "#         CSV_DF['time'][i]=datetime.strptime(aus, '%Y-%m-%d %H:%M:%S').time()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unire i tre file .csv e rilevare il file differenza tra Vin e Vbat maggiore di 1200 mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = CSV_DF.union(CSV_DF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.union(CSV_DF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3007222, 22)\n"
     ]
    }
   ],
   "source": [
    "print((result.count(), len(result.columns)))\n",
    "# print((CSV_DF.count(), len(CSV_DF.columns)))\n",
    "# print((CSV_DF2.count(), len(CSV_DF2.columns)))\n",
    "# print((CSV_DF1.count()), len(CSV_DF1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=result.withColumn(\"Diff_V\", result[\"VIN\"]-result[\"VBATT\"])\n",
    "result=result.withColumn(\"Critical\",F.when(result.Diff_V>1200, \"Yes\").otherwise(\"No\"))\n",
    "#result=result.withColumn(\"Critical\",F.when(result.Diff_V<1200),\"Normal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To verify results \n",
    "#result.filter(result.Diff_V>1200).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print only the Critical cases \n",
    "Critical_host=result.filter(result.Diff_V>1200)\n",
    "Critical_host.toPandas().to_csv('mycsv.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.toPandas().to_csv('Final_November1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparazione dei dati per il machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast column type \n",
    "result=result.drop(\"date\")\n",
    "result = result.withColumn(\"VIN\", result[\"VIN\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"IIN\", result[\"IIN\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"VOUT\", result[\"VOUT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"VBATT\", result[\"VBATT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"IBATT\", result[\"IBATT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"TEMP\", result[\"TEMP\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"JP\", result[\"JP\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"CNT\", result[\"CNT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"POWER\", result[\"POWER\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"BCK1CURR\", result[\"BCK1CURR\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"STS\", result[\"STS\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"MIN\", result[\"MIN\"].cast(IntegerType()))\n",
    "####################################################################\n",
    "result = result.withColumn(\"CURRLIGHT\", result[\"CURRLIGHT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"BRIGHTNESS\", result[\"BRIGHTNESS\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"PAN1VOLT\", result[\"PAN1VOLT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"PAN1CURR\", result[\"PAN1CURR\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"BCK1VOLT\", result[\"BCK1VOLT\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"RSSI\", result[\"RSSI\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"Diff_V\", result[\"Diff_V\"].cast(IntegerType()))\n",
    "result = result.withColumn(\"AUTOBCKLIGHT\", result[\"AUTOBCKLIGHT\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [t[0] for t in result.dtypes if t[1] == 'int']\n",
    "result.select(numeric_features).describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_data = result.select(numeric_features).toPandas()\n",
    "# axs = scatter_matrix(numeric_data, figsize=(8, 8));\n",
    "# n = len(numeric_data.columns)\n",
    "# for i in range(n):\n",
    "#     v = axs[i, 0]\n",
    "#     v.yaxis.label.set_rotation(0)\n",
    "#     v.yaxis.label.set_ha('right')\n",
    "#     v.set_yticks(())\n",
    "#     h = axs[n-1, i]\n",
    "#     h.xaxis.label.set_rotation(90)\n",
    "#     h.set_xticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['host_id', 'time']\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = 'Critical', outputCol = 'label')\n",
    "stages += [label_stringIdx]\n",
    "\n",
    "numericCols = numeric_features\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipelineModel.transform(result)\n",
    "selectedCols = ['label', 'features'] + cols\n",
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.take(5), columns=df.columns)#.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
